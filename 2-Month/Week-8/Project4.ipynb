{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed3800c8",
   "metadata": {},
   "source": [
    "Model Evaluation and Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fadc06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ddb87fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer(as_frame=True)\n",
    "X = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a240bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (569, 30)\n",
      "Features: ['mean radius', 'mean texture', 'mean perimeter', 'mean area', 'mean smoothness', 'mean compactness', 'mean concavity', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'radius error', 'texture error', 'perimeter error', 'area error', 'smoothness error', 'compactness error', 'concavity error', 'concave points error', 'symmetry error', 'fractal dimension error', 'worst radius', 'worst texture', 'worst perimeter', 'worst area', 'worst smoothness', 'worst compactness', 'worst concavity', 'worst concave points', 'worst symmetry', 'worst fractal dimension']\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset shape:\", X.shape)\n",
    "print(\"Features:\", list(X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e71264e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b74e352",
   "metadata": {},
   "source": [
    "Baseline Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e52dce20",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_rf = RandomForestClassifier(random_state=42)\n",
    "baseline_rf.fit(X_train, y_train)\n",
    "y_pred_base = baseline_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74709a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Baseline Model Metrics =====\n",
      "Accuracy: 0.9649122807017544\n",
      "Precision: 0.958904109589041\n",
      "Recall: 0.9859154929577465\n",
      "F1-Score: 0.9722222222222222\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95        43\n",
      "           1       0.96      0.99      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.97      0.96      0.96       114\n",
      "weighted avg       0.97      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n===== Baseline Model Metrics =====\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_base))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_base))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_base))\n",
    "print(\"F1-Score:\", f1_score(y_test, y_pred_base))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_base))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99aeec0d",
   "metadata": {},
   "source": [
    "Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1b0cbff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation Accuracy (5-fold): 0.9560937742586555\n"
     ]
    }
   ],
   "source": [
    "cv_scores = cross_val_score(baseline_rf, X, y, cv=5)\n",
    "print(\"Cross-validation Accuracy (5-fold):\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496f456c",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "675bc891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Best Model After GridSearchCV =====\n",
      "Best Parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Best Cross-validation Score: 0.9626373626373625\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"n_estimators\": [50, 100, 200],\n",
    "    \"max_depth\": [None, 5, 10],\n",
    "    \"min_samples_split\": [2, 5, 10]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n===== Best Model After GridSearchCV =====\")\n",
    "print(\"Best Parameters:\", grid.best_params_)\n",
    "print(\"Best Cross-validation Score:\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e16e74",
   "metadata": {},
   "source": [
    "Evaluate tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1fe0e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Tuned Model Metrics =====\n",
      "Accuracy: 0.9649122807017544\n",
      "Precision: 0.958904109589041\n",
      "Recall: 0.9859154929577465\n",
      "F1-Score: 0.9722222222222222\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95        43\n",
      "           1       0.96      0.99      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.97      0.96      0.96       114\n",
      "weighted avg       0.97      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_rf = grid.best_estimator_\n",
    "y_pred_best = best_rf.predict(X_test)\n",
    "\n",
    "print(\"\\n===== Tuned Model Metrics =====\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_best))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_best))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_best))\n",
    "print(\"F1-Score:\", f1_score(y_test, y_pred_best))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_best))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
